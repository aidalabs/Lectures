{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tensorflow**"
      ],
      "metadata": {
        "id": "JYYsLGXsVNst"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Tensorflow 개요**"
      ],
      "metadata": {
        "id": "eiGm9JmFWdhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-1. Tensorflow란?"
      ],
      "metadata": {
        "id": "cDYDQENVWq_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Google에서 개발한 딥러닝과 기계 학습을 위한 오픈소스 라이브러리\n",
        "- 2015년에 공개하여 지금까지 계속 업데이트 및 지원이 진행 중임"
      ],
      "metadata": {
        "id": "aGSK7cEIWu-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-2. Tensorflow의 기능적 소개\n",
        "- 그래프 형태로 수치 연산을 하는 라이브러리\n",
        "- '텐서(tensor)'라는 데이터 구조를 사용함\n",
        "- 텐서\n",
        "    - 수학적으로는 쉽게 말하면 다차원 배열을 나타냄\n",
        "    - TensorFlow에서는 이러한 텐서를 노드(node)라고 부르는 연산들 사이를 흐르는 데이터로 사용함\n",
        "- 즉, TensorFlow는 데이터의 흐름을 그래프로 표현하고, 이 그래프를 계산하여 딥러닝 모델을 학습하고 실행하는 도구\n",
        "    - 그래프는 연산(operation)들과 변수(variable)들로 구성됨\n",
        "    - 변수들은 학습 중에 업데이트되는 모델의 파라미터를 의미함"
      ],
      "metadata": {
        "id": "7MZnVGVUZOLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-3. TensorFlow의 장점\n",
        "- 딥러닝 모델을 구성하고, 학습시키며, 추론(inference)하는 작업을 보다 간단하고 유연하게 만들 수 있음\n",
        "- GPU나 TPU와 같은 가속기를 활용하여 계산을 빠르게 처리할 수 있기 때문에, 대용량 데이터와 복잡한 모델에도 적용하기 용이함\n",
        "- 쉽고 다양한 API를 제공하므로 사용자가 원하는 수준에서 모델을 구성할 수 있음\n",
        "- 이미 구현된 많은 딥러닝 모델과 레이어를 포함하여 고수준의 추상화된 기능을 제공함\n",
        "- 자유롭게 커스터마이징이 가능함\n",
        "- 다른 라이브러리나 프레임워크와 쉽게 통합하여 사용할 수 있음"
      ],
      "metadata": {
        "id": "jxmKUpL4ZPJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1-4. Tensorflow의 사용 현황\n",
        "- TensorFlow는 딥러닝과 머신러닝의 다양한 분야에서 널리 사용되고 있으며, 컴퓨터 비전, 자연어 처리, 음성 인식 등 다양한 애플리케이션에 적용되고 있음\n",
        "- 활발한 커뮤니티가 많으며, 이러한 커뮤니티를 통해 지속적인 지원과 발전이 이루어지고 있음"
      ],
      "metadata": {
        "id": "ToO9XRdbZO8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Tensor**"
      ],
      "metadata": {
        "id": "26L1nXg0WKK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "L9HqnnQ2vBD2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-1. 기본 텐서 생성"
      ],
      "metadata": {
        "id": "jEI0nBt6uTcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Rank-0 Tensor (=Scala)\n",
        "    - 단일 값을 포함\n",
        "    - 축은 없음"
      ],
      "metadata": {
        "id": "SMZtA90buZ4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be an int32 tensor by default; see \"dtypes\" below.\n",
        "rank_0_tensor = tf.constant(4)\n",
        "print(rank_0_tensor)"
      ],
      "metadata": {
        "id": "GBMpmIf3uY_-",
        "outputId": "c052815e-928e-4798-91c9-2a898a3c2c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Rank-1 Tensor (=Vector)\n",
        "    - List와 동일\n",
        "    - 하나의 축이 있음"
      ],
      "metadata": {
        "id": "ovQz9ktGuxZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make this a float tensor.\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "print(rank_1_tensor)"
      ],
      "metadata": {
        "id": "n6rH3R1Tuvnh",
        "outputId": "299097f7-073a-4711-edc6-0aa4bc16ab65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Rank-2 Tensor (=Matrix)\n",
        "    - 두 개의 축이 있음"
      ],
      "metadata": {
        "id": "hG1HnDn3vLta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to be specific, you can set the dtype (see below) at creation time\n",
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]], dtype=tf.float16)\n",
        "print(rank_2_tensor)"
      ],
      "metadata": {
        "id": "4CaagelvvJI7",
        "outputId": "b7fe3310-9ae9-42e8-853a-7d8ecce8cbcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Rank-3 Tensor\n",
        "    - 세 개의 축이 있음"
      ],
      "metadata": {
        "id": "OmdL9OdOvZon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There can be an arbitrary number of\n",
        "# axes (sometimes called \"dimensions\")\n",
        "rank_3_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "print(rank_3_tensor)"
      ],
      "metadata": {
        "id": "HVsHOl2fvR5y",
        "outputId": "8fe4d65e-088f-4548-a5e0-2cbde52b4fe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- np.array 또는 tensor.numpy 메서드를 사용하여 텐서를 NumPy 배열로 변환할 수 있음"
      ],
      "metadata": {
        "id": "kFMJkp1svh50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "JU3C6amSvsIX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(rank_2_tensor)"
      ],
      "metadata": {
        "id": "dY5esukrvgxB",
        "outputId": "9c3e98bb-219a-48e4-809a-a0784ddaa2c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.],\n",
              "       [5., 6.]], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank_2_tensor.numpy()"
      ],
      "metadata": {
        "id": "lpEobAk7vwQr",
        "outputId": "4e791489-1528-4932-cdf3-7254f8be08c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.],\n",
              "       [5., 6.]], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 텐서는 주로 float, int로 구성되지만 복소수, 문자열을 포함하는 유형도 있음\n",
        "- 기본 tf.Tensor 클래스에서는 텐서가 \"직사각형\"이어야 함. 즉, 각 축을 따라 모든 요소의 크기가 같음. 그러나 다양한 형상을 처리할 수 있는 특수 유형의 텐서가 존재함\n",
        "    - 비정형 텐서\n",
        "    - 희소 텐서"
      ],
      "metadata": {
        "id": "4syYQrFfv6IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 텐서의 연산\n",
        "    - 덧셈, 요소별 곱셈 및 행렬 곱셈을 포함하여 텐서에 대한 기본 산술을 수행할 수 있음"
      ],
      "metadata": {
        "id": "8zRtH_a24bQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
        "\n",
        "print(tf.add(a, b), \"\\n\")\n",
        "print(tf.multiply(a, b), \"\\n\")\n",
        "print(tf.matmul(a, b), \"\\n\")"
      ],
      "metadata": {
        "id": "k4NfdLb5v06D",
        "outputId": "ba3f9e5a-f21c-4f8d-acca-48732e1c24ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a + b, \"\\n\") # element-wise addition\n",
        "print(a * b, \"\\n\") # element-wise multiplication\n",
        "print(a @ b, \"\\n\") # matrix multiplication"
      ],
      "metadata": {
        "id": "axuvr__m4l7L",
        "outputId": "46ae9934-6cee-48d5-abaf-22f5c8231b8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
        "\n",
        "# Find the largest value\n",
        "print(tf.reduce_max(c))\n",
        "# Find the index of the largest value\n",
        "print(tf.math.argmax(c))\n",
        "# Compute the softmax\n",
        "print(tf.nn.softmax(c))"
      ],
      "metadata": {
        "id": "ABnsxivG4ouL",
        "outputId": "18c6faad-119d-4279-8563-37bd42f58829",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[2.6894143e-01 7.3105860e-01]\n",
            " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TensorFlow 함수가 Tensor를 입력으로 받을 것을 예상하는 경우, 이 함수는 tf.convert_to_tensor를 사용하여 Tensor로 변환할 수 있는 모든 항목을 허용함"
      ],
      "metadata": {
        "id": "56f4HYj05AdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.convert_to_tensor([1,2,3])"
      ],
      "metadata": {
        "id": "uAeE-8_t4rVk",
        "outputId": "13850790-4628-4cbc-d40c-fe750f0d2a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_max([1,2,3])"
      ],
      "metadata": {
        "id": "dxqQV6UV40sC",
        "outputId": "df0c0091-5e54-4f73-c235-74910a9eade6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_max(np.array([1,2,3]))"
      ],
      "metadata": {
        "id": "E1wNwoJz42ZE",
        "outputId": "f7466cd0-9ce9-4361-e6a9-2e8a67fa1b10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=3>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. 형상 정보"
      ],
      "metadata": {
        "id": "bwbwZ5av5fh9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 형상: 텐서의 각 차원의 길이(요소의 수)\n",
        "- 순위: 텐서 축의 수(스칼라는 순위가 0이고 벡터의 순위는 1이며 행렬의 순위는 2)\n",
        "- 축 또는 차원: 텐서의 특정 차원\n",
        "- 크기: 텐서의 총 항목 수, 형상 벡터 요소의 곱\n",
        "- 참고: \"2차원 텐서\"에 대한 참조가 있을 수 있지만, 순위-2 텐서가 2D 공간을 말하지는 않음"
      ],
      "metadata": {
        "id": "FdYWA7CB5o3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])"
      ],
      "metadata": {
        "id": "BBnaRsd944oy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
      ],
      "metadata": {
        "id": "m6K4iTxh6N0U",
        "outputId": "a79b5dba-b350-42c6-94ab-0990bb2325e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of every element: <dtype: 'float32'>\n",
            "Number of axes: 4\n",
            "Shape of tensor: (3, 2, 4, 5)\n",
            "Elements along axis 0 of tensor: 3\n",
            "Elements along the last axis of tensor: 5\n",
            "Total number of elements (3*2*4*5):  120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tensor.ndim 및 Tensor.shape 속성은 Tensor 객체를 반환하지 않음\n",
        "- Tensor가 필요한 경우 tf.rank 또는 tf.shape 함수를 사용해야 함\n",
        "- 이 둘의 차이는 그래프를 작성할 때 중요함"
      ],
      "metadata": {
        "id": "Zx-K7ze96VKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.rank(rank_4_tensor)"
      ],
      "metadata": {
        "id": "NUkYQkJB6Pn7",
        "outputId": "6e2226ce-4b07-4cfd-fdb8-0c4314a4b68d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.shape(rank_4_tensor)"
      ],
      "metadata": {
        "id": "uImdp-jU6kNa",
        "outputId": "a4774041-6b28-4c23-9c8d-e09ed1f4e95b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([3, 2, 4, 5], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 축은 종종 인덱스로 참조하지만, 항상 각 축의 의미를 추적해야 함\n",
        "- 축이 전역에서 로컬로 정렬되는 경우\n",
        "    - 배치 축이 먼저 오고 그 다음에 공간 차원과 각 위치의 특성이 마지막에 옴\n",
        "    - 이러한 방식으로 특성 벡터는 연속적인 메모리 영역임"
      ],
      "metadata": {
        "id": "I6bXSV816pb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-3. 인덱싱"
      ],
      "metadata": {
        "id": "2TdYv5rv7ftL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단일 축 인덱싱\n",
        "\t- TensorFlow는 Python의 목록 또는 문자열 인덱싱과 마찬가지로 표준 Python 인덱싱 규칙과 NumPy 인덱싱의 기본 규칙을 따름\n",
        "        - 인덱스는 0에서 시작\n",
        "        - 음수 인덱스는 끝에서부터 거꾸로 계산\n",
        "        - 콜론(:)은 start:stop:step 슬라이스에 사용\n",
        "        - 스칼라를 사용하여 인덱싱하면 축이 제거됨\n",
        "        - : 슬라이스를 사용하여 인덱싱하면 축이 유지됨"
      ],
      "metadata": {
        "id": "DShObhDj8DAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ],
      "metadata": {
        "id": "L3oFkMYN6mVE",
        "outputId": "f0fa066b-7f5c-4f63-dc0a-ace5d728f8ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First:\", rank_1_tensor[0].numpy())\n",
        "print(\"Second:\", rank_1_tensor[1].numpy())\n",
        "print(\"Last:\", rank_1_tensor[-1].numpy())"
      ],
      "metadata": {
        "id": "byGnawUR8GsI",
        "outputId": "af248fde-5f56-4669-8f54-ce3479833ed2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First: 0\n",
            "Second: 1\n",
            "Last: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
        "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
        "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
        "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
        "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
        "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
      ],
      "metadata": {
        "id": "YzUKeP3H8Lfq",
        "outputId": "f2539653-8b9e-4a67-d8ff-e4d5c66f54c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
            "Before 4: [0 1 1 2]\n",
            "From 4 to the end: [ 3  5  8 13 21 34]\n",
            "From 2, before 7: [1 2 3 5 8]\n",
            "Every other item: [ 0  1  3  8 21]\n",
            "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 다축 인덱싱\n",
        "\t- 더 높은 순위의 텐서는 여러 인덱스를 전달하여 인덱싱됨\n",
        "\t- 단일 축의 경우에서와 정확히 같은 규칙이 각 축에 독립적으로 적용됨\n",
        "    - 각 인덱스에 정수를 전달하면 결과는 스칼라가 됨\n",
        "    - 정수와 슬라이스의 조합을 사용하여 인덱싱할 수 있음"
      ],
      "metadata": {
        "id": "fa9bBlLO87Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_2_tensor.numpy())"
      ],
      "metadata": {
        "id": "27ADWEBN85pj",
        "outputId": "62699a57-fad6-469a-c9c4-6067bbf2ec79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull out a single value from a 2-rank tensor\n",
        "print(rank_2_tensor[1, 1].numpy())"
      ],
      "metadata": {
        "id": "q933eSlI9Tdl",
        "outputId": "4b8e5b53-d445-4939-8d68-80845da79007",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get row and column tensors\n",
        "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
        "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
        "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
        "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
        "print(\"Skip the first row:\")\n",
        "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
      ],
      "metadata": {
        "id": "PGDcaw8n9VC8",
        "outputId": "3e9293cd-ddbe-4364-9eb9-9c0766fcef34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second row: [3. 4.]\n",
            "Second column: [2. 4. 6.]\n",
            "Last row: [5. 6.]\n",
            "First item in last column: 2.0\n",
            "Skip the first row:\n",
            "[[3. 4.]\n",
            " [5. 6.]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3축 텐서의 예\n",
        "print(rank_3_tensor[:, :, 4])"
      ],
      "metadata": {
        "id": "u3pWk3uV9WmE",
        "outputId": "3e1eff0e-884c-46e8-979b-144b7d6d5958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4  9]\n",
            " [14 19]\n",
            " [24 29]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-4. 형상 조작하기"
      ],
      "metadata": {
        "id": "T8A_MXSq9gYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape returns a `TensorShape` object that shows the size along each axis\n",
        "x = tf.constant([[1], [2], [3]])\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "8o2RAQuW9dXA",
        "outputId": "23f82b99-29de-40fc-a297-6eace22c2f46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can convert this object into a Python list, too\n",
        "print(x.shape.as_list())"
      ],
      "metadata": {
        "id": "sQOezvvf9ntc",
        "outputId": "a8795562-7f9a-4854-97a7-005948b51076",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can reshape a tensor to a new shape.\n",
        "# Note that you're passing in a list\n",
        "reshaped = tf.reshape(x, [1, 3])"
      ],
      "metadata": {
        "id": "ab8c9bXH9pTl"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(reshaped.shape)"
      ],
      "metadata": {
        "id": "nlK31EUt9rua",
        "outputId": "0af3682e-7fb4-43f8-f515-4e048125b2d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_3_tensor)"
      ],
      "metadata": {
        "id": "lPKK26XJ9tKc",
        "outputId": "b44afa3c-807d-4526-aa51-83e7b1f9b7bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
        "print(tf.reshape(rank_3_tensor, [-1]))"
      ],
      "metadata": {
        "id": "kjgifwOK9vNr",
        "outputId": "ecfbfaf3-0962-4796-80e3-aa8336fd7e98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 일반적으로, tf.reshape의 합리적인 용도는 인접한 축을 결합하거나 분할하는 것뿐임(또는 1을 추가/제거)"
      ],
      "metadata": {
        "id": "RK2swUxv92eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 3x2x5 텐서의 경우, 슬라이스가 혼합되지 않으므로 (3x2)x5 또는 3x (2x5)로 재구성하는 것이 합리적\n",
        "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
        "print(tf.reshape(rank_3_tensor, [3, -1]))"
      ],
      "metadata": {
        "id": "VaT5nR009w2j",
        "outputId": "5ecbe922-6a12-4c62-ae55-78b54c3a69c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]\n",
            " [15 16 17 18 19]\n",
            " [20 21 22 23 24]\n",
            " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 형상을 변경하면 같은 총 요소 수를 가진 새로운 형상에 대해 \"작동\"하지만, 축의 순서를 고려하지 않으면 별로 쓸모가 없음\n",
        "- tf.reshape에서 축 교환이 작동하지 않으면, tf.transpose를 수행해야 합"
      ],
      "metadata": {
        "id": "xtTlWQIO-Sv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bad examples: don't do this\n",
        "\n",
        "# You can't reorder axes with reshape.\n",
        "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\")\n",
        "\n",
        "# This is a mess\n",
        "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
        "\n",
        "# This doesn't work at all\n",
        "try:\n",
        "  tf.reshape(rank_3_tensor, [7, -1])\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ],
      "metadata": {
        "id": "4GjXLgc--Cid",
        "outputId": "8b1d35ef-e3fa-4fe2-da0e-e14d000c9d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
            "\n",
            "InvalidArgumentError: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-5. DTypes"
      ],
      "metadata": {
        "id": "Jm5-rlmw-zWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tf.Tensor의 데이터 유형을 검사하려면, Tensor.dtype 속성을 사용함\n",
        "- Python 객체에서 tf.Tensor를 만들 때 선택적으로 데이터 유형을 지정할 수 있음\n",
        "- TensorFlow는 데이터를 나타낼 수 있는 데이터 유형을 선택함\n",
        "    - TensorFlow는 Python 정수를 tf.int32로, 파이썬 부동 소수점 숫자를 tf.float32로 변환함\n",
        "    - 또는 TensorFlow는 NumPy가 배열로 변환할 때 사용하는 것과 같은 규칙을 사용함"
      ],
      "metadata": {
        "id": "o7Vvmmfm_Efe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
        "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
        "# Now, cast to an uint8 and lose the decimal precision\n",
        "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
        "print(the_u8_tensor)"
      ],
      "metadata": {
        "id": "bkPWM2BA-Y49",
        "outputId": "ed25f197-24ab-4fbf-d872-0d20136b9c4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-6. 브로드캐스팅"
      ],
      "metadata": {
        "id": "BRW7llDnAxXP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 브로드캐스팅이란?\n",
        "    - 특정 조건에서 작은 텐서는 결합된 연산을 실행할 때 더 큰 텐서에 맞게 자동으로 \"확장(streched)\"되는 것\n",
        "    - NumPy의 해당 특성에서 빌린 개념\n",
        "\n",
        "    - 가장 간단하고 가장 일반적인 경우\n",
        "        - 스칼라에 텐서를 곱하거나 추가하려고 할 때\n",
        "        - 이 경우, 스칼라는 다른 인수와 같은 형상으로 브로드캐스트됨"
      ],
      "metadata": {
        "id": "gTk1PrnFA2A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ],
      "metadata": {
        "id": "Yi2LdkimAvwu",
        "outputId": "8acb2a3b-adc1-422f-b52e-b7009404d06b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# These are the same computations\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(1, 5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(tf.multiply(x, y))"
      ],
      "metadata": {
        "id": "gPVIPp6hB868",
        "outputId": "70bc547f-c7cf-43ce-c048-77a185e7fce4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1]\n",
            " [2]\n",
            " [3]], shape=(3, 1), dtype=int32) \n",
            "\n",
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 브로드캐스팅이 없는 같은 연산\n",
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ],
      "metadata": {
        "id": "lBOVh4kMCF9M",
        "outputId": "0522af21-36d9-4c04-c15f-ce192483c7f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. 변수**"
      ],
      "metadata": {
        "id": "AkcUCCbPCieV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-1. 변수 만들기"
      ],
      "metadata": {
        "id": "S6K3HA_7Co_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "my_variable = tf.Variable(my_tensor)\n",
        "\n",
        "# Variables can be all kinds of types, just like tensors\n",
        "bool_variable = tf.Variable([False, False, False, True])\n",
        "complex_variable = tf.Variable([5 + 4j, 6 + 1j])"
      ],
      "metadata": {
        "id": "YU4yn8IlCNEZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape: \", my_variable.shape)\n",
        "print(\"DType: \", my_variable.dtype)\n",
        "print(\"As NumPy: \", my_variable.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVG3jlUwC5dq",
        "outputId": "a654fd5e-8351-4b72-9fb2-3e2bbd5a6476"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  (2, 2)\n",
            "DType:  <dtype: 'float32'>\n",
            "As NumPy:  [[1. 2.]\n",
            " [3. 4.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"A variable:\", my_variable)\n",
        "print(\"\\nViewed as a tensor:\", tf.convert_to_tensor(my_variable))\n",
        "print(\"\\nIndex of highest value:\", tf.math.argmax(my_variable))\n",
        "\n",
        "# This creates a new tensor; it does not reshape the variable.\n",
        "print(\"\\nCopying and reshaping: \", tf.reshape(my_variable, [1,4]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O0j1js2C87z",
        "outputId": "9d23799f-4895-4788-ccca-7958c7c617af"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A variable: <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[1., 2.],\n",
            "       [3., 4.]], dtype=float32)>\n",
            "\n",
            "Viewed as a tensor: tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]], shape=(2, 2), dtype=float32)\n",
            "\n",
            "Index of highest value: tf.Tensor([1 1], shape=(2,), dtype=int64)\n",
            "\n",
            "Copying and reshaping:  tf.Tensor([[1. 2. 3. 4.]], shape=(1, 4), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.Variable([2.0, 3.0])\n",
        "# This will keep the same dtype, float32\n",
        "a.assign([1, 2])\n",
        "# Not allowed as it resizes the variable:\n",
        "try:\n",
        "  a.assign([1.0, 2.0, 3.0])\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLonAfrtDDiH",
        "outputId": "18e04ef2-816b-42cb-ad00-7cf4afa65761"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: Cannot assign value to variable ' Variable:0': Shape mismatch.The variable shape (2,), and the assigned value shape (3,) are incompatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.Variable([2.0, 3.0])\n",
        "# Create b based on the value of a\n",
        "b = tf.Variable(a)\n",
        "a.assign([5, 6])\n",
        "\n",
        "# a and b are different\n",
        "print(a.numpy())\n",
        "print(b.numpy())\n",
        "\n",
        "# There are other versions of assign\n",
        "print(a.assign_add([2,3]).numpy())  # [7. 9.]\n",
        "print(a.assign_sub([7,9]).numpy())  # [0. 0.]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jhPa1hADAtJ",
        "outputId": "05f4c479-fd9a-4a28-9740-57c413da7077"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5. 6.]\n",
            "[2. 3.]\n",
            "[7. 9.]\n",
            "[0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-2. 수명주기와 이름 지정 및 감시"
      ],
      "metadata": {
        "id": "qOP1nu7tCrjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a and b; they will have the same name but will be backed by\n",
        "# different tensors.\n",
        "a = tf.Variable(my_tensor, name=\"Mark\")\n",
        "# A new variable with the same name, but different value\n",
        "# Note that the scalar add is broadcast\n",
        "b = tf.Variable(my_tensor + 1, name=\"Mark\")\n",
        "\n",
        "# These are elementwise-unequal, despite having the same name\n",
        "print(a == b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUwcvTmmCwCx",
        "outputId": "152de5af-617b-4fce-9b0d-bf21dad7b9cb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[False False]\n",
            " [False False]], shape=(2, 2), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "step_counter = tf.Variable(1, trainable=False)"
      ],
      "metadata": {
        "id": "YaRFIyLzDGIy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3-3. 변수 및 텐서 배치"
      ],
      "metadata": {
        "id": "RTBHKkuCCxTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('CPU:0'):\n",
        "\n",
        "  # Create some tensors\n",
        "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE6M9jWcCzmF",
        "outputId": "efe3098b-a343-4e1b-96fd-3cf3289db921"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('CPU:0'):\n",
        "  a = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "  b = tf.Variable([[1.0, 2.0, 3.0]])\n",
        "\n",
        "with tf.device('GPU:0'):\n",
        "  # Element-wise multiply\n",
        "  k = a * b\n",
        "\n",
        "print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aPKWVqXDKhc",
        "outputId": "51bb2e9c-1a3a-4566-d9ee-522d72c41e9c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1.  4.  9.]\n",
            " [ 4. 10. 18.]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W85h-kSbDeZp"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Tensorflow를 사용하는 과정**"
      ],
      "metadata": {
        "id": "AvZXqgm3Deuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 필요한 패키지를 가져온다.\n",
        "- 텐서를 만들고 사용한다.\n",
        "- GPU 가속을 사용한다.\n",
        "- tf.data.Dataset로 데이터 파이프라인을 구축한다."
      ],
      "metadata": {
        "id": "7hVZzi_oak5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-1. 필요한 패키지(Tensorflow) 가져오기"
      ],
      "metadata": {
        "id": "gOnU1_Kjaxck"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2NHJ-737UlAA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-2. Tensor 만들고 사용하기"
      ],
      "metadata": {
        "id": "RdJjPkwsVJtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tensor\n",
        "    - 다차원 배열\n",
        "    - NumPy ndarray 객체와 유사하게 tf.Tensor 객체에도 dtype(데이터 유형)과 shape(형상)가 있음\n",
        "    - tf.Tensor는 가속기 메모리(예: GPU)에 상주할 수 있음\n",
        "    - tf.math.add, tf.linalg.matmul, tf.linalg.inv 등 다양한 연산 라이브러리 지원\n",
        "    - 연산 라이브러리는 기본 Python 유형을 자동으로 변환하여 사용/적용 가능"
      ],
      "metadata": {
        "id": "F2iUMEFZEJXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.math.add(1, 2))\n",
        "print(tf.math.add([1, 2], [3, 4]))\n",
        "print(tf.math.square(5))\n",
        "print(tf.math.reduce_sum([1, 2, 3]))\n",
        "\n",
        "# Operator overloading is also supported\n",
        "print(tf.math.square(2) + tf.math.square(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC18KMiSUsEL",
        "outputId": "de59f08a-8e17-47ec-8670-34fdb92efcb9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor([4 6], shape=(2,), dtype=int32)\n",
            "tf.Tensor(25, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(13, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.linalg.matmul([[1]], [[2, 3]])\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj5ovL-0UsBS",
        "outputId": "0f6915cd-75d9-449c-dd9a-d6dc5c4d46d3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[2 3]], shape=(1, 2), dtype=int32)\n",
            "(1, 2)\n",
            "<dtype: 'int32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Numpy와의 호환성\n",
        "    - 간단한 TensorFlow tf.Tensor와 NumPy ndarray 사이의 변환\n",
        "        - 텐서플로 연산은 자동으로 NumPy 배열을 텐서로 변환함\n",
        "        - NumPy 연산은 자동으로 텐서를 NumPy 배열로 변환함\n",
        "    - 텐서는 .numpy() 메서드(method)를 호출하여 NumPy 배열로 변환할 수 있음\n",
        "        - tf.Tensor와 배열은 메모리 표현을 공유하기 때문에 이러한 변환은 일반적으로는 간단함\n",
        "    - 텐서와 NumPy 배열의 차이\n",
        "        - tf.Tensor는 GPU 메모리에 저장될 수 있고, NumPy 배열은 항상 호스트 메모리에 저장됨\n",
        "        - 따라서 이러한 변환이 항상 가능한 것은 아님\n",
        "        - GPU 메모리와 호스트 메모리에 각각 저장된 배열을 변환하려면 GPU에서 호스트 메모리로 복사하는 작업이 필요함"
      ],
      "metadata": {
        "id": "So2_3_IRFJR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "ndarray = np.ones([3, 3])\n",
        "\n",
        "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
        "tensor = tf.math.multiply(ndarray, 42)\n",
        "print(tensor)\n",
        "\n",
        "\n",
        "print(\"And NumPy operations convert Tensors to NumPy arrays automatically\")\n",
        "print(np.add(tensor, 1))\n",
        "\n",
        "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
        "print(tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSPIkmS8Ur-U",
        "outputId": "0df1bba1-4a6f-4a1b-a40f-3b39502d6c19"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow operations convert numpy arrays to Tensors automatically\n",
            "tf.Tensor(\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
            "And NumPy operations convert Tensors to NumPy arrays automatically\n",
            "[[43. 43. 43.]\n",
            " [43. 43. 43.]\n",
            " [43. 43. 43.]]\n",
            "The .numpy() method explicitly converts a Tensor to a numpy array\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-3. GPU 가속 사용하기"
      ],
      "metadata": {
        "id": "SJxDzl7QJcq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPU 가속의 사용\n",
        "    - 대부분의 TensorFlow 연산은 GPU를 사용하여 가속화됨\n",
        "    - 어떠한 코드를 명시하지 않아도, TensorFlow는 연산을 위해 CPU 또는 GPU를 사용할 것인지를 자동으로 결정함\n",
        "    - 필요 시 텐서를 CPU와 GPU 메모리 사이에서 복사\n",
        "    - 연산에 의해 생성된 텐서는 전형적으로 연산이 실행된 장치의 메모리에 의해 실행됨"
      ],
      "metadata": {
        "id": "4E9Uri6OGULE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.random.uniform([3, 3])\n",
        "\n",
        "print(\"Is there a GPU available: \"),\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "print(\"Is the Tensor on GPU #0:  \"),\n",
        "print(x.device.endswith('GPU:0'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs4JNrzcUr7b",
        "outputId": "10e93cf3-c122-42cf-b7e5-29b33ab8c1f9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is there a GPU available: \n",
            "[]\n",
            "Is the Tensor on GPU #0:  \n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 장치 명\n",
        "    - Tensor.device는 텐서를 구성하고 있는 호스트 장치의 풀네임을 제공함\n",
        "    - 제공되는 호스트 장치 명\n",
        "        - 프로그램이 실행중인 호스트의 네트워크 주소 및 해당 호스트 내의 장치와 같은 많은 세부 정보를 인코딩\n",
        "        - 텐서플로 프로그램의 분산 실행에 필요함\n",
        "        - 텐서가 호스트의 N번째 GPU에 놓여지면 문자열은 GPU:<N>으로 끝남\n",
        "    - 명시적 장치 배치\n",
        "        - TensorFlow에서 배치란 개별 연산이 실행을 위해 장치에 할당(배치)되는 방식을 나타냄\n",
        "        - 명시적인 지침이 없으면 TensorFlow는 연산을 실행할 장치를 자동으로 결정하고 필요한 경우 해당 장치에 텐서를 복사함\n",
        "        - 명시적으로 배치하려면 tf.device 컨텍스트 관리자를 사용하여 특정 장치에 배치 가능"
      ],
      "metadata": {
        "id": "t5hqhcTiH1D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def time_matmul(x):\n",
        "  start = time.time()\n",
        "  for loop in range(10):\n",
        "    tf.linalg.matmul(x, x)\n",
        "\n",
        "  result = time.time()-start\n",
        "\n",
        "  print(\"10 loops: {:0.2f}ms\".format(1000*result))\n",
        "\n",
        "# Force execution on CPU\n",
        "print(\"On CPU:\")\n",
        "with tf.device(\"CPU:0\"):\n",
        "  x = tf.random.uniform([1000, 1000])\n",
        "  assert x.device.endswith(\"CPU:0\")\n",
        "  time_matmul(x)\n",
        "\n",
        "# Force execution on GPU #0 if available\n",
        "if tf.config.list_physical_devices(\"GPU\"):\n",
        "  print(\"On GPU:\")\n",
        "  with tf.device(\"GPU:0\"): # Or GPU:1 for the 2nd GPU, GPU:2 for the 3rd etc.\n",
        "    x = tf.random.uniform([1000, 1000])\n",
        "    assert x.device.endswith(\"GPU:0\")\n",
        "    time_matmul(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRCcUTAfUr4u",
        "outputId": "0c9c3f4f-b768-4e91-9375-8d5a8ce73931"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On CPU:\n",
            "10 loops: 684.89ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-4. tf.data.Dataset로 데이터 파이프라인을 구축하기"
      ],
      "metadata": {
        "id": "CeEmH9cQJsDR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 세트의 사용\n",
        "    - tf.data.Dataset API를 사용하여 모델에 데이터를 공급하기 위한 파이프라인을 구축\n",
        "    - tf.data.Dataset\n",
        "        - 모델의 훈련 또는 평가 루프에 데이터를 제공할 단순하고 재사용 가능한 부분으로부터 성능이 뛰어나고 복잡한 입력 파이프라인을 구축하는 데 사용됨"
      ],
      "metadata": {
        "id": "dA8AUvj8Iq8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 소스 데이터세트 생성하기\n",
        "    1. tf.data.Dataset.from_tensors, tf.data.Dataset.from_tensor_slices 등의 팩토리 함수 중 하나를 사용\n",
        "    2. tf.data.TextLineDataset 또는 tf.data.TFRecordDataset와 같은 파일에서 읽는 객체를 사용"
      ],
      "metadata": {
        "id": "TuKKMQMiJ1Hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Create a CSV file\n",
        "import tempfile\n",
        "_, filename = tempfile.mkstemp()\n",
        "\n",
        "with open(filename, 'w') as f:\n",
        "  f.write(\"\"\"Line 1\n",
        "Line 2\n",
        "Line 3\n",
        "  \"\"\")\n",
        "\n",
        "ds_file = tf.data.TextLineDataset(filename)"
      ],
      "metadata": {
        "id": "QaK_KyZ4Ur14"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터세트 변환 적용\n",
        "    - tf.data.Dataset.map, tf.data.Dataset.batch 및 tf.data.Dataset.shuffle과 같은 변환 함수를 사용하여 데이터세트 레코드에 변환 적용"
      ],
      "metadata": {
        "id": "DPfQ5dadJVb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_tensors = ds_tensors.map(tf.math.square).shuffle(2).batch(2)\n",
        "\n",
        "ds_file = ds_file.batch(2)"
      ],
      "metadata": {
        "id": "xhVpYiGgUrzJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 반복하기\n",
        "    - tf.data.Dataset는 레코드 순회를 지원하는 반복 가능한 객체"
      ],
      "metadata": {
        "id": "k_P0MpgFKGKD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Elements of ds_tensors:')\n",
        "for x in ds_tensors:\n",
        "  print(x)\n",
        "\n",
        "print('\\nElements in ds_file:')\n",
        "for x in ds_file:\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH1yWi3LUrwQ",
        "outputId": "8a864952-61d1-4a8d-e008-f6d01d12f86d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of ds_tensors:\n",
            "tf.Tensor([1 9], shape=(2,), dtype=int32)\n",
            "tf.Tensor([ 4 25], shape=(2,), dtype=int32)\n",
            "tf.Tensor([16 36], shape=(2,), dtype=int32)\n",
            "\n",
            "Elements in ds_file:\n",
            "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
            "tf.Tensor([b'Line 3' b'  '], shape=(2,), dtype=string)\n"
          ]
        }
      ]
    }
  ]
}